+++
# Date this page was created.
date = "2017-12-27"

# Project title.
title = "Exploitation of multiple-echoes Lidars on-board UGV"

# Project summary to display on homepage.
summary = "Research-Stay in [LAAS-CNRS](https://www.laas.fr/public/). Collaboration with [Simon LACROIX](http://homepages.laas.fr/simon/HomePage/Home.html) (Research scientist in mobile robotics) from [RIS](https://www.laas.fr/public/fr/ris) team."

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "lidar.png"

# Tags: can be used for filtering projects.
# Example: `tags = ["machine-learning", "deep-learning"]`
tags = ["LiDAR", "ROS", "Perception", "Machine-Learning"]

# Optional external URL for project (replaces project detail page).
external_link = ""
#


# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "minnie.jpg"
caption = "GitHup Repository"

+++

LiDAR technologies are now the sensor of choice in robotics to provide range data. While most LiDARs only provide a mere point cloud by associating a single distance to each measure, some can provide further information, such as the multiple echoes generated by the environment enlightened by the LiDAR beam and the associated returned energy. The physics underlying LiDARs is indeed more complex than single time of flight distance measurements the beam is not infinitely narrow, and the reflected energy is a function of the impacted materials nature and orientation.

Mobile Robots need to understand the environment which its are moving, the multi-echo ability of some LiDAR instruments is an important element to improve the scene classification tasks given the extra information for each beam during all the flight, in addition to the received signal features as pulse-width and intensity. In this project, we developed a 3D scanning system for an UGV based on a LiDAR LD-MRS and  equipped with a pan-tilt unit. For the first stage, we started with a characterization of both devices and and with the [software acquisition](https://github.com/HaroldMurcia/LDMRS-PTU_LAAS") programming based on [GenoM3](https://www.openrobots.org/wiki/genom3) and [ROS](http://www.ros.org). In the second stage, a kinematic model and a calibration system are proposed based on experimental parameter-estimation methods to improve the quality of the acquired point cloud. Finally, a simple scene classification is developed; for our purpose in UGV outdoor environment, we started from a labeled manual segmentation to use supervised classification techniques. Once the data set is defined the point clouds are sub-sampled in voxels by using octrees from the [OctoMap](https://octomap.github.io) library. Each sub-sampled voxel content a local point cloud about which features are calculated for training and prediction processes.

Future work involves the evaluation of descriptors based on pulse width information and the academic divulgation of the results.

[GitHub Repository](https://github.com/HaroldMurcia/LDMRS-PTU_LAAS" )
